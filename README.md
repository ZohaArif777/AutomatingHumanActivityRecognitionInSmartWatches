This Android application uses a pre-trained TensorFlow Lite model to predict human activities (e.g., walking, sitting, sleeping) based on sensor data from a CSV file.
Users can load CSV files, perform predictions, and view results with an interactive UI.
Accessibility features such as voice commands, high contrast mode, and larger text support are included.
The app demonstrates real-time on-device ML inference using TFLite.
Ideal for research, demo, or educational purposes involving mobile machine learning.

## ğŸš€ Features
- ğŸ§  Human Activity Recognition (HAR) using a TFLite model.
- ğŸ“ Load CSV files for inference.
- ğŸ“Š Displays prediction confidence and a chart of results.
- ğŸ¤ Voice command support.
- â™¿ Accessibility options: High contrast theme & large text toggle.
- ğŸ“‰ Real-time progress indication during model inference.
